config_file: config_file/stage2.yaml
filename: desc_esol_output
seed: 42
mode: eval
strategy_name: null
iupac_prediction: false
ckpt_path: null
num_beams: 1
do_sample: false
max_len: 512
min_len: 8
length_penalty: 1.0
llm_tune: freeze
peft_config: null
peft_dir: ''
save_every_n_epochs: 10
load_in_8bit: false
lora_r: 8
lora_alpha: 32
lora_dropout: 0.1
weight_decay: 0.05
init_lr: 5.0e-05
min_lr: 5.0e-06
warmup_lr: 5.0e-07
warmup_steps: 1000
lr_decay_rate: 0.9
scheduler: linear_warmup_cosine_lr
optimizer: adamw
stage_path: /workspace/llamo_checkpoint.ckpt
init_checkpoint: ''
caption_eval_epoch: 1
num_workers: 2
batch_size: 1
inference_batch_size: 1
root_train: /workspace/LLaMo/esol/
root_eval: /workspace/LLaMo/esol/
filtered_cid_path: null
accelerator: gpu
devices: 0,1,2,3,4,5,6,7
precision: bf16-mixed
max_epochs: 10
accumulate_grad_batches: 1
check_val_every_n_epoch: 1
project: linear
mlp_depth: 2
