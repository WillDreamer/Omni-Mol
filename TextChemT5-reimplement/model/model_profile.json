{
    "Num Param": 225019625,
    "Model structure": [
        "GraphT5ForConditionalGeneration(",
        "  (graph_tower): GraphTower(",
        "    (gnn): GNN_graphpred(",
        "      (molecule_node_model): GNN(",
        "        (atom_encoder): AtomEncoder(",
        "          (atom_embedding_list): ModuleList(",
        "            (0): Embedding(119, 300)",
        "            (1): Embedding(4, 300)",
        "            (2-3): 2 x Embedding(12, 300)",
        "            (4): Embedding(10, 300)",
        "            (5-6): 2 x Embedding(6, 300)",
        "            (7-8): 2 x Embedding(2, 300)",
        "          )",
        "        )",
        "        (gnns): ModuleList(",
        "          (0-4): 5 x GINConv()",
        "        )",
        "        (batch_norms): ModuleList(",
        "          (0-4): 5 x BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)",
        "        )",
        "      )",
        "    )",
        "  )",
        "  (mm_projector): NaiveLinear(",
        "    (weight): Linear(in_features=300, out_features=768, bias=True)",
        "  )",
        "  (language_model): T5ForConditionalGeneration(",
        "    (shared): Embedding(32128, 768)",
        "    (encoder): T5Stack(",
        "      (embed_tokens): Embedding(32128, 768)",
        "      (block): ModuleList(",
        "        (0): T5Block(",
        "          (layer): ModuleList(",
        "            (0): T5LayerSelfAttention(",
        "              (SelfAttention): T5Attention(",
        "                (q): Linear(in_features=768, out_features=768, bias=False)",
        "                (k): Linear(in_features=768, out_features=768, bias=False)",
        "                (v): Linear(in_features=768, out_features=768, bias=False)",
        "                (o): Linear(in_features=768, out_features=768, bias=False)",
        "                (relative_attention_bias): Embedding(32, 12)",
        "              )",
        "              (layer_norm): T5LayerNorm()",
        "              (dropout): Dropout(p=0.1, inplace=False)",
        "            )",
        "            (1): T5LayerFF(",
        "              (DenseReluDense): T5DenseActDense(",
        "                (wi): Linear(in_features=768, out_features=3072, bias=False)",
        "                (wo): Linear(in_features=3072, out_features=768, bias=False)",
        "                (dropout): Dropout(p=0.1, inplace=False)",
        "                (act): ReLU()",
        "              )",
        "              (layer_norm): T5LayerNorm()",
        "              (dropout): Dropout(p=0.1, inplace=False)",
        "            )",
        "          )",
        "        )",
        "        (1-11): 11 x T5Block(",
        "          (layer): ModuleList(",
        "            (0): T5LayerSelfAttention(",
        "              (SelfAttention): T5Attention(",
        "                (q): Linear(in_features=768, out_features=768, bias=False)",
        "                (k): Linear(in_features=768, out_features=768, bias=False)",
        "                (v): Linear(in_features=768, out_features=768, bias=False)",
        "                (o): Linear(in_features=768, out_features=768, bias=False)",
        "              )",
        "              (layer_norm): T5LayerNorm()",
        "              (dropout): Dropout(p=0.1, inplace=False)",
        "            )",
        "            (1): T5LayerFF(",
        "              (DenseReluDense): T5DenseActDense(",
        "                (wi): Linear(in_features=768, out_features=3072, bias=False)",
        "                (wo): Linear(in_features=3072, out_features=768, bias=False)",
        "                (dropout): Dropout(p=0.1, inplace=False)",
        "                (act): ReLU()",
        "              )",
        "              (layer_norm): T5LayerNorm()",
        "              (dropout): Dropout(p=0.1, inplace=False)",
        "            )",
        "          )",
        "        )",
        "      )",
        "      (final_layer_norm): T5LayerNorm()",
        "      (dropout): Dropout(p=0.1, inplace=False)",
        "    )",
        "    (decoder): T5Stack(",
        "      (embed_tokens): Embedding(32128, 768)",
        "      (block): ModuleList(",
        "        (0): T5Block(",
        "          (layer): ModuleList(",
        "            (0): T5LayerSelfAttention(",
        "              (SelfAttention): T5Attention(",
        "                (q): Linear(in_features=768, out_features=768, bias=False)",
        "                (k): Linear(in_features=768, out_features=768, bias=False)",
        "                (v): Linear(in_features=768, out_features=768, bias=False)",
        "                (o): Linear(in_features=768, out_features=768, bias=False)",
        "                (relative_attention_bias): Embedding(32, 12)",
        "              )",
        "              (layer_norm): T5LayerNorm()",
        "              (dropout): Dropout(p=0.1, inplace=False)",
        "            )",
        "            (1): T5LayerCrossAttention(",
        "              (EncDecAttention): T5Attention(",
        "                (q): Linear(in_features=768, out_features=768, bias=False)",
        "                (k): Linear(in_features=768, out_features=768, bias=False)",
        "                (v): Linear(in_features=768, out_features=768, bias=False)",
        "                (o): Linear(in_features=768, out_features=768, bias=False)",
        "              )",
        "              (layer_norm): T5LayerNorm()",
        "              (dropout): Dropout(p=0.1, inplace=False)",
        "            )",
        "            (2): T5LayerFF(",
        "              (DenseReluDense): T5DenseActDense(",
        "                (wi): Linear(in_features=768, out_features=3072, bias=False)",
        "                (wo): Linear(in_features=3072, out_features=768, bias=False)",
        "                (dropout): Dropout(p=0.1, inplace=False)",
        "                (act): ReLU()",
        "              )",
        "              (layer_norm): T5LayerNorm()",
        "              (dropout): Dropout(p=0.1, inplace=False)",
        "            )",
        "          )",
        "        )",
        "        (1-11): 11 x T5Block(",
        "          (layer): ModuleList(",
        "            (0): T5LayerSelfAttention(",
        "              (SelfAttention): T5Attention(",
        "                (q): Linear(in_features=768, out_features=768, bias=False)",
        "                (k): Linear(in_features=768, out_features=768, bias=False)",
        "                (v): Linear(in_features=768, out_features=768, bias=False)",
        "                (o): Linear(in_features=768, out_features=768, bias=False)",
        "              )",
        "              (layer_norm): T5LayerNorm()",
        "              (dropout): Dropout(p=0.1, inplace=False)",
        "            )",
        "            (1): T5LayerCrossAttention(",
        "              (EncDecAttention): T5Attention(",
        "                (q): Linear(in_features=768, out_features=768, bias=False)",
        "                (k): Linear(in_features=768, out_features=768, bias=False)",
        "                (v): Linear(in_features=768, out_features=768, bias=False)",
        "                (o): Linear(in_features=768, out_features=768, bias=False)",
        "              )",
        "              (layer_norm): T5LayerNorm()",
        "              (dropout): Dropout(p=0.1, inplace=False)",
        "            )",
        "            (2): T5LayerFF(",
        "              (DenseReluDense): T5DenseActDense(",
        "                (wi): Linear(in_features=768, out_features=3072, bias=False)",
        "                (wo): Linear(in_features=3072, out_features=768, bias=False)",
        "                (dropout): Dropout(p=0.1, inplace=False)",
        "                (act): ReLU()",
        "              )",
        "              (layer_norm): T5LayerNorm()",
        "              (dropout): Dropout(p=0.1, inplace=False)",
        "            )",
        "          )",
        "        )",
        "      )",
        "      (final_layer_norm): T5LayerNorm()",
        "      (dropout): Dropout(p=0.1, inplace=False)",
        "    )",
        "    (lm_head): Linear(in_features=768, out_features=32128, bias=False)",
        "  )",
        ")"
    ],
    "Activated paramteres": [
        "language_model.shared.weight",
        "language_model.encoder.block.0.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.0.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.0.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.0.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight",
        "language_model.encoder.block.0.layer.0.layer_norm.weight",
        "language_model.encoder.block.0.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.0.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.0.layer.1.layer_norm.weight",
        "language_model.encoder.block.1.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.1.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.1.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.1.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.1.layer.0.layer_norm.weight",
        "language_model.encoder.block.1.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.1.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.1.layer.1.layer_norm.weight",
        "language_model.encoder.block.2.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.2.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.2.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.2.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.2.layer.0.layer_norm.weight",
        "language_model.encoder.block.2.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.2.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.2.layer.1.layer_norm.weight",
        "language_model.encoder.block.3.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.3.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.3.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.3.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.3.layer.0.layer_norm.weight",
        "language_model.encoder.block.3.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.3.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.3.layer.1.layer_norm.weight",
        "language_model.encoder.block.4.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.4.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.4.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.4.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.4.layer.0.layer_norm.weight",
        "language_model.encoder.block.4.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.4.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.4.layer.1.layer_norm.weight",
        "language_model.encoder.block.5.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.5.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.5.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.5.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.5.layer.0.layer_norm.weight",
        "language_model.encoder.block.5.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.5.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.5.layer.1.layer_norm.weight",
        "language_model.encoder.block.6.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.6.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.6.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.6.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.6.layer.0.layer_norm.weight",
        "language_model.encoder.block.6.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.6.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.6.layer.1.layer_norm.weight",
        "language_model.encoder.block.7.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.7.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.7.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.7.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.7.layer.0.layer_norm.weight",
        "language_model.encoder.block.7.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.7.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.7.layer.1.layer_norm.weight",
        "language_model.encoder.block.8.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.8.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.8.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.8.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.8.layer.0.layer_norm.weight",
        "language_model.encoder.block.8.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.8.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.8.layer.1.layer_norm.weight",
        "language_model.encoder.block.9.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.9.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.9.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.9.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.9.layer.0.layer_norm.weight",
        "language_model.encoder.block.9.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.9.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.9.layer.1.layer_norm.weight",
        "language_model.encoder.block.10.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.10.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.10.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.10.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.10.layer.0.layer_norm.weight",
        "language_model.encoder.block.10.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.10.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.10.layer.1.layer_norm.weight",
        "language_model.encoder.block.11.layer.0.SelfAttention.q.weight",
        "language_model.encoder.block.11.layer.0.SelfAttention.k.weight",
        "language_model.encoder.block.11.layer.0.SelfAttention.v.weight",
        "language_model.encoder.block.11.layer.0.SelfAttention.o.weight",
        "language_model.encoder.block.11.layer.0.layer_norm.weight",
        "language_model.encoder.block.11.layer.1.DenseReluDense.wi.weight",
        "language_model.encoder.block.11.layer.1.DenseReluDense.wo.weight",
        "language_model.encoder.block.11.layer.1.layer_norm.weight",
        "language_model.encoder.final_layer_norm.weight",
        "language_model.decoder.block.0.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.0.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.0.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.0.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight",
        "language_model.decoder.block.0.layer.0.layer_norm.weight",
        "language_model.decoder.block.0.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.0.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.0.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.0.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.0.layer.1.layer_norm.weight",
        "language_model.decoder.block.0.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.0.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.0.layer.2.layer_norm.weight",
        "language_model.decoder.block.1.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.1.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.1.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.1.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.1.layer.0.layer_norm.weight",
        "language_model.decoder.block.1.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.1.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.1.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.1.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.1.layer.1.layer_norm.weight",
        "language_model.decoder.block.1.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.1.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.1.layer.2.layer_norm.weight",
        "language_model.decoder.block.2.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.2.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.2.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.2.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.2.layer.0.layer_norm.weight",
        "language_model.decoder.block.2.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.2.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.2.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.2.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.2.layer.1.layer_norm.weight",
        "language_model.decoder.block.2.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.2.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.2.layer.2.layer_norm.weight",
        "language_model.decoder.block.3.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.3.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.3.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.3.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.3.layer.0.layer_norm.weight",
        "language_model.decoder.block.3.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.3.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.3.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.3.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.3.layer.1.layer_norm.weight",
        "language_model.decoder.block.3.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.3.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.3.layer.2.layer_norm.weight",
        "language_model.decoder.block.4.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.4.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.4.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.4.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.4.layer.0.layer_norm.weight",
        "language_model.decoder.block.4.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.4.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.4.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.4.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.4.layer.1.layer_norm.weight",
        "language_model.decoder.block.4.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.4.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.4.layer.2.layer_norm.weight",
        "language_model.decoder.block.5.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.5.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.5.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.5.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.5.layer.0.layer_norm.weight",
        "language_model.decoder.block.5.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.5.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.5.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.5.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.5.layer.1.layer_norm.weight",
        "language_model.decoder.block.5.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.5.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.5.layer.2.layer_norm.weight",
        "language_model.decoder.block.6.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.6.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.6.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.6.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.6.layer.0.layer_norm.weight",
        "language_model.decoder.block.6.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.6.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.6.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.6.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.6.layer.1.layer_norm.weight",
        "language_model.decoder.block.6.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.6.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.6.layer.2.layer_norm.weight",
        "language_model.decoder.block.7.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.7.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.7.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.7.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.7.layer.0.layer_norm.weight",
        "language_model.decoder.block.7.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.7.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.7.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.7.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.7.layer.1.layer_norm.weight",
        "language_model.decoder.block.7.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.7.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.7.layer.2.layer_norm.weight",
        "language_model.decoder.block.8.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.8.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.8.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.8.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.8.layer.0.layer_norm.weight",
        "language_model.decoder.block.8.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.8.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.8.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.8.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.8.layer.1.layer_norm.weight",
        "language_model.decoder.block.8.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.8.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.8.layer.2.layer_norm.weight",
        "language_model.decoder.block.9.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.9.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.9.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.9.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.9.layer.0.layer_norm.weight",
        "language_model.decoder.block.9.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.9.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.9.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.9.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.9.layer.1.layer_norm.weight",
        "language_model.decoder.block.9.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.9.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.9.layer.2.layer_norm.weight",
        "language_model.decoder.block.10.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.10.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.10.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.10.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.10.layer.0.layer_norm.weight",
        "language_model.decoder.block.10.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.10.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.10.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.10.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.10.layer.1.layer_norm.weight",
        "language_model.decoder.block.10.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.10.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.10.layer.2.layer_norm.weight",
        "language_model.decoder.block.11.layer.0.SelfAttention.q.weight",
        "language_model.decoder.block.11.layer.0.SelfAttention.k.weight",
        "language_model.decoder.block.11.layer.0.SelfAttention.v.weight",
        "language_model.decoder.block.11.layer.0.SelfAttention.o.weight",
        "language_model.decoder.block.11.layer.0.layer_norm.weight",
        "language_model.decoder.block.11.layer.1.EncDecAttention.q.weight",
        "language_model.decoder.block.11.layer.1.EncDecAttention.k.weight",
        "language_model.decoder.block.11.layer.1.EncDecAttention.v.weight",
        "language_model.decoder.block.11.layer.1.EncDecAttention.o.weight",
        "language_model.decoder.block.11.layer.1.layer_norm.weight",
        "language_model.decoder.block.11.layer.2.DenseReluDense.wi.weight",
        "language_model.decoder.block.11.layer.2.DenseReluDense.wo.weight",
        "language_model.decoder.block.11.layer.2.layer_norm.weight",
        "language_model.decoder.final_layer_norm.weight"
    ]
}